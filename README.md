# Facial Expression Recognition

This repository contains a Facial Expression Recognition project built using a custom Convolutional Neural Network (CNN) in TensorFlow, paired with a C++ GUI frontend using the Qt framework.

---

üîπ **Overview**

This project classifies human facial expressions into one of seven emotion categories:

- Angry  
- Disgust  
- Fear  
- Happy  
- Neutral  
- Sad  
- Surprise  

It uses a trained deep learning model to predict the emotion from a given facial image. The application includes a GUI that allows users to select an image file, run the model, and display the result interactively.

---

üîπ **Model Details**

- **Architecture**: Custom Convolutional Neural Network (CNN)
- **Accuracy**: ~75% on test set
- **Input Size**: 64x64 grayscale face image
- **Language**: Python (for backend & model inference)
- **Model File**:
  - `facial_expression.h5` ‚Äì trained Keras model file

---

üîπ **Preprocessing Techniques**

The following preprocessing steps are applied to the input image before prediction:

- Face detection using Haar Cascades (`haarcascade_frontalface_default.xml`)
- Conversion to grayscale
- Cropping and resizing the face region to 64x64
- Normalization (handled internally by the model if applicable)

If no face is detected in the image, the program returns an error message.

This logic is implemented in `model.py`.

---

üîπ **Application Frontend**
- **Frontend Language**: C++
- **Libraries Used**:
  - `QApplication`
  - `QProcess`
  - `QLabel`
  - `QFileDialog`
  - `QPixmap`
- **Executable**: Qt-based GUI application

---

‚ö†Ô∏è **Note**:
The GUI application is developed using the Qt framework and is currently tested on Linux systems.
---

üîπ **How It Works:**
1. User selects an image through the Qt GUI.
2. The image path is passed to the Python backend using `QProcess`.
3. `model.py`:
   - Detects and preprocesses the face.
   - Loads the CNN model (`facial_expression.h5`).
   - Runs the prediction.
4. The predicted emotion is returned and displayed in the GUI.

---

üîπ **Requirements**

**Python(Backend):**:
- tensorflow
- opencv-python
- numpy
- splitfolders
- matplotlib

**Frontend:**
Frontend Language: C++
Libraries Used:
- QApplication
- QProcess (used to call Python backend),
Executable: qt_app (your will get this executable file after compiling the main.cpp),
To download the C++ libraries, use this command in terminal: sudo apt install qtbase5-dev,
To compile the main.cpp file, command: g++ -fPIC main.cpp -o qt_app pkg-config --cflags --libs Qt5Widgets

**Usage:**
1. Clone the repository.
2. Ensure you're on a Linux system with Qt and Python installed.
3. Open or build `main.cpp` using Qt Creator or CMake.
4. Place `facial_expression.h5` and `model.py` in the same directory as the compiled executable.
5. Run the application.
6. Select an image to classify its facial expression.

---

üîπ **Notes**
- Only one face is processed per image (currently selects the first detected face).
- The prediction is most accurate when the face is clearly visible and front-facing.
- To improve real-world performance, the model can be enhanced with data augmentation and real-time webcam input.

